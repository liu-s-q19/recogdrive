import time
import torch
import os
from navsim.common.dataclasses import TrajectorySampling
from navsim.agents.recogdrive.recogdrive_agent import ReCogDriveAgent

# ---------------- é…ç½®åŒºåŸŸ ----------------
CHECKPOINT_PATH = "/nfs/dataset-ofs-prediction/rl_lab/leidianqiao/code/recogdrive/exp/recogdrive_stage3_rl_training_16gpus_bs8/lightning_logs/version_0/checkpoints/epoch=9-step=6650.ckpt"
VLM_PATH = "/nfs/dataset-ofs-prediction/rl_lab/leidianqiao/code/recogdrive/ckpt/ReCogDrive-VLM-8B"
DEVICE_ID = 0
# ------------------------------------------

def main():
    device = torch.device(f"cuda:{DEVICE_ID}")
    print(f"ğŸš€ Starting Split Benchmark on {torch.cuda.get_device_name(device)}...")

    # 1. åˆå§‹åŒ– Agent
    print("Loading Model...")
    traj_sampling = TrajectorySampling(time_horizon=4.0, interval_length=0.5)
    agent = ReCogDriveAgent(
        traj_sampling,
        checkpoint_path=CHECKPOINT_PATH,
        vlm_path=VLM_PATH,
        cam_type='single',
        vlm_type='internvl',
        dit_type='small',
        sampling_method='ddim',
        cache_mode=False,         
        cache_hidden_state=False, 
        vlm_size='large',        
        grpo=False,
    ).to(device)
    agent.initialize()
    agent.eval()

    # è·å– InternVL æ ¸å¿ƒæ¨¡å‹
    # agent.backbone æ˜¯ RecogDriveBackbone
    # agent.backbone.model æ˜¯ HuggingFace InternVLModel
    internvl_model = agent.backbone.model 

    # ---------------- 2. æ„é€ è¾“å…¥ ----------------
    # æ¨¡æ‹Ÿè¾“å…¥ï¼š1å¼ å›¾, 448x448
    dummy_images = torch.randn(1, 3, 448, 448, dtype=torch.bfloat16).to(device)
    dummy_questions = ["<image>\nPredict trajectory."] 
    dummy_num_patches_list = [1] # 1ä¸ªpatch

    # ---------------- 3. åˆ†æ®µæµ‹é€Ÿ ----------------
    loops = 50
    print(f"\nRunning {loops} loops for breakdown analysis...")

    # --- A. æµ‹è¯•çº¯è§†è§‰ç¼–ç  (Vision Encoder Only) ---
    # InternVL çš„è§†è§‰éƒ¨åˆ†å« vision_model
    start_vis = torch.cuda.Event(enable_timing=True)
    end_vis = torch.cuda.Event(enable_timing=True)
    
    start_vis.record()
    with torch.no_grad():
        for _ in range(loops):
            # ç›´æ¥è°ƒç”¨å†…éƒ¨çš„ vision_model
            # è¾“å…¥: (B*Num_Patches, C, H, W) -> (1, 3, 448, 448)
            _ = internvl_model.vision_model(dummy_images)
    end_vis.record()
    torch.cuda.synchronize()
    avg_vis = start_vis.elapsed_time(end_vis) / loops

    # --- B. æµ‹è¯•æ•´ä½“ VLM (Total VLM) ---
    # æˆ‘ä»¬ä¹‹å‰æµ‹è¿‡çš„é‚£ä¸ª 478ms
    start_total = torch.cuda.Event(enable_timing=True)
    end_total = torch.cuda.Event(enable_timing=True)
    
    start_total.record()
    with torch.no_grad():
        for _ in range(loops):
            _ = agent.backbone(dummy_images, dummy_questions, dummy_num_patches_list)
    end_total.record()
    torch.cuda.synchronize()
    avg_total = start_total.elapsed_time(end_total) / loops

    # --- C. è®¡ç®— LLM æ¨ç†æ—¶é—´ ---
    # LLM æ—¶é—´ = æ€»æ—¶é—´ - è§†è§‰æ—¶é—´
    avg_llm = avg_total - avg_vis

    # ---------------- 4. æ‰“å°ç»™è€å¸ˆçš„æŠ¥å‘Š ----------------
    print("\n" + "="*50)
    print(f"ğŸ”¬ VLM Internal Breakdown (InternVL-8B)")
    print("="*50)
    print(f"1. Vision Encoder (ViT-6B):  {avg_vis:.2f} ms  ({avg_vis/avg_total*100:.1f}%)")
    print(f"2. LLM Inference (Qwen/Llama): {avg_llm:.2f} ms  ({avg_llm/avg_total*100:.1f}%)")
    print("-" * 50)
    print(f"ğŸ“¦ Total VLM Latency:          {avg_total:.2f} ms")
    print("="*50)
    print("\n[è§£é‡Š]")
    print("Vision Encoder: è´Ÿè´£å°†å›¾åƒåƒç´ è½¬æ¢ä¸ºè§†è§‰ç‰¹å¾ (InternVL çš„è§†è§‰å¡”å¾ˆå¤§ï¼Œçº¦60äº¿å‚æ•°)ã€‚")
    print("LLM Inference:  è´Ÿè´£å¤„ç† Prompt å¹¶ç»“åˆè§†è§‰ç‰¹å¾è¾“å‡º Hidden Stateã€‚")

if __name__ == "__main__":
    main()