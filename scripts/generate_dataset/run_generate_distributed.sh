#!/bin/bash
# ----------------- 1. åŸºç¡€çŽ¯å¢ƒåˆå§‹åŒ– -----------------
# åŠ è½½ conda é…ç½®
source /home/luban/miniconda3/etc/profile.d/conda.sh
# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
conda activate navsim

# åˆ‡æ¢åˆ°ä»£ç æ ¹ç›®å½• (NFS å…±äº«ç›®å½•)
PROJECT_ROOT="/nfs/dataset-ofs-prediction/rl_lab/leidianqiao/code/recogdrive"
cd $PROJECT_ROOT
echo "Working Directory: $(pwd)"

# ----------------- 2. è‡ªåŠ¨åŒ–åˆ†å¸ƒå¼é…ç½® -----------------
# [A] æ˜¾å¡é…ç½®
GPUS_PER_NODE=8
# å¦‚æžœå¹³å°æ²¡æœ‰æ³¨å…¥ NNODES å˜é‡ï¼Œé»˜è®¤å°è¯•è‡ªåŠ¨æŽ¢æµ‹æˆ–è®¾ä¸º 2
if [ -n "$PET_MASTER_ADDR" ]; then
    echo ">> Detected Luban/PET Environment"
    MASTER_ADDR=$PET_MASTER_ADDR
    MASTER_PORT=${PET_MASTER_PORT:-29500}
    NODE_RANK=${DISTRIBUTED_NODE_RANK:-0}
    NNODES=${PET_NNODES:-1}
elif [ -n "$VC_MASTER_HOSTS" ]; then
    echo ">> Detected Volcano Environment"
    MASTER_ADDR=$(echo $VC_MASTER_HOSTS | cut -d',' -f1)
    MASTER_PORT=${MASTER_PORT:-29500}
    NODE_RANK=${VC_TASK_INDEX:-0}
    NNODES=$(echo $VC_MASTER_HOSTS | tr ',' '\n' | wc -l)
elif [ -n "$MLP_WORKER_0_HOST" ]; then
    echo ">> Detected Standard MLP Environment"
    MASTER_ADDR=$MLP_WORKER_0_HOST
    MASTER_PORT=${MLP_WORKER_0_PORT:-29500}
    NODE_RANK=$MLP_ROLE_INDEX
    NNODES=${MLP_WORKER_NUM:-1}
else
    echo ">> Warning: No distributed variables found. Fallback to Localhost (Single Node)."
    MASTER_ADDR="127.0.0.1"
    MASTER_PORT=29500
    NODE_RANK=0
    NNODES=1
fi

# ä½ çš„é›†ç¾¤æ˜¯2æœº8å¡ï¼Œå¦‚æžœè‡ªåŠ¨æŽ¢æµ‹ä¸å‡†ï¼Œè¿™é‡Œå–æ¶ˆæ³¨é‡Šå¼ºåˆ¶æŒ‡å®š
# NNODES=2 

echo "=================================================="
echo "   ðŸš€ Cluster Generation Job Start"
echo "=================================================="
echo "Master Node: $MASTER_ADDR:$MASTER_PORT"
echo "My Rank:     $NODE_RANK"
echo "Total Nodes: $NNODES"
echo "GPUs/Node:   $GPUS_PER_NODE"
echo "Total GPUs:  $((NNODES * GPUS_PER_NODE))"
echo "=================================================="

# ----------------- 3. çŽ¯å¢ƒå˜é‡å¯¼å‡º -----------------
# è¿™é‡Œçš„ navtrain åªæ˜¯ä¸ºäº†è®© Hydra èƒ½æ‰¾åˆ°ä¸€ä¸ªåŸºç¡€é…ç½®æ–‡ä»¶åˆå§‹åŒ–
# å®žé™…ä¸Šæˆ‘ä»¬çš„ Python ä»£ç é‡Œå·²ç»é‡å†™äº† filter é€»è¾‘ï¼Œæ‰€ä»¥è¿™é‡Œç”¨ navtrain æ²¡é—®é¢˜
TRAIN_TEST_SPLIT=navtrain 

# æ¨¡åž‹è·¯å¾„
MODEL_PATH="/nfs/dataset-ofs-prediction/rl_lab/leidianqiao/code/recogdrive/ckpt/ReCogDrive-VLM-8B" 

export NUPLAN_MAP_VERSION="nuplan-maps-v1.0"
export NUPLAN_MAPS_ROOT="$PROJECT_ROOT/data/navsim/maps"
export NAVSIM_EXP_ROOT="$PROJECT_ROOT/exp"
export NAVSIM_DEVKIT_ROOT="$PROJECT_ROOT"
export OPENSCENE_DATA_ROOT="$PROJECT_ROOT/data/navsim"
export NAVSIM_DATA_ROOT=$OPENSCENE_DATA_ROOT
export PYTHONPATH="$(pwd):${PYTHONPATH}"

# ç½‘ç»œé€šä¿¡ä¼˜åŒ– (é˜²æ­¢å¤šæœºå¡æ­»ï¼Œå¼ºåˆ¶ TCP)
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=0
export NCCL_SHM_DISABLE=0
export NCCL_SOCKET_FAMILY=AF_INET

# ----------------- 4. å¯åŠ¨åˆ†å¸ƒå¼ç”Ÿæˆ -----------------
LOG_FILE="generation_rank${NODE_RANK}.log"

echo "Starting torchrun on Node ${NODE_RANK}..."

# ã€å…³é”®ä¿®æ­£ç‚¹ã€‘ï¼šè¿™é‡Œä½¿ç”¨ +model_path è€Œä¸æ˜¯ model_path
# å› ä¸º model_path å¾ˆå¯èƒ½ä¸åœ¨åŽŸå§‹çš„ navtrain.yaml é‡Œï¼Œç”¨ + è¡¨ç¤ºæ–°å¢žå‚æ•°
torchrun \
    --nnodes=$NNODES \
    --node_rank=$NODE_RANK \
    --master_addr=$MASTER_ADDR \
    --master_port=$MASTER_PORT \
    --nproc_per_node=$GPUS_PER_NODE \
    scripts/generate_dataset/generate_reasoning_gt_distributed.py \
    --config-name $TRAIN_TEST_SPLIT \
    +model_path=$MODEL_PATH \
    > $LOG_FILE 2>&1

if [ $? -ne 0 ]; then
    echo "[ERROR] Torchrun failed on Node ${NODE_RANK}! Check $LOG_FILE."
    exit 1
fi

echo "Node ${NODE_RANK} finished generation."

# ----------------- 5. ç»“æžœåˆå¹¶ (ä»…åœ¨ Master èŠ‚ç‚¹æ‰§è¡Œ) -----------------
if [ "$NODE_RANK" -eq 0 ]; then
    echo "=================================================="
    echo "Waiting for all nodes to sync..."
    # ç¨å¾®å¤šç¡ä¸€ä¼šï¼Œé˜²æ­¢ NFS æ–‡ä»¶ç³»ç»Ÿæœ‰å»¶è¿Ÿï¼Œå¯¼è‡´ Rank 0 çœ‹ä¸åˆ°å…¶ä»–èŠ‚ç‚¹ç”Ÿæˆçš„æ–‡ä»¶
    sleep 30 
    
    echo ">> Master Node (Rank 0): Start Merging..."
    
    python -c "
import json
import glob
import os

# è¿™é‡Œçš„åå­—å¯ä»¥æ ¹æ®ä½ æƒ³è¦çš„æœ€ç»ˆæ–‡ä»¶åä¿®æ”¹
output_name = 'reasoning_gt_trainval_full.json'
files = glob.glob('reasoning_gt_part_*.json')

print(f'Found {len(files)} part files.')
data = {}
for f in files:
    try:
        part_data = json.load(open(f))
        data.update(part_data)
        print(f'Merged {f}: {len(part_data)} samples')
    except Exception as e:
        print(f'[ERROR] merging {f}: {e}')

with open(output_name, 'w') as f:
    json.dump(data, f, indent=4) # åŠ äº† indent=4 è®©æœ€ç»ˆç»“æžœä¹Ÿæ¼‚äº®

print(f'[SUCCESS] Final merged file: {output_name} ({len(data)} total samples)')
" >> $LOG_FILE 2>&1
    
    echo "Done! Check $LOG_FILE for details."
fi