#!/bin/bash
# åŠ è½½ conda é…ç½®
source /home/luban/miniconda3/etc/profile.d/conda.sh
# æ¿€æ´»ä½ çš„è™šæ‹ŸçŽ¯å¢ƒ
conda activate navsim
# åˆ‡æ¢åˆ°ä»£ç æ ¹ç›®å½• (éžå¸¸é‡è¦ï¼Œå¦åˆ™ python æ‰¾ä¸åˆ°æ¨¡å—)
cd /nfs/dataset-ofs-prediction/rl_lab/leidianqiao/code/recogdrive


# æ‰“å°æ‰€æœ‰çŽ¯å¢ƒå˜é‡åˆ°æ—¥å¿—ï¼Œå¸®æˆ‘ä»¬æ‰¾ IP å˜é‡å
printenv > env_debug.log
echo "Environment variables saved to env_debug.log"
#!/bin/bash

# ----------------- 1. è·¯å¾„ä¸ŽåŸºç¡€é…ç½® -----------------
# ä½ çš„ NFS ä»£ç æ ¹ç›®å½•
PROJECT_ROOT="/nfs/dataset-ofs-prediction/rl_lab/leidianqiao/code/recogdrive"
TRAIN_TEST_SPLIT=navtrain

# å¯¼å‡ºçŽ¯å¢ƒå˜é‡
export NUPLAN_MAP_VERSION="nuplan-maps-v1.0"
export NUPLAN_MAPS_ROOT="$PROJECT_ROOT/data/navsim/maps"
export NAVSIM_EXP_ROOT="$PROJECT_ROOT/exp"
export NAVSIM_DEVKIT_ROOT="$PROJECT_ROOT"
export OPENSCENE_DATA_ROOT="$PROJECT_ROOT/data/navsim"

# æ¨¡åž‹ä¸Žç¼“å­˜è·¯å¾„
VLM_PATH="$PROJECT_ROOT/ckpt/ReCogDrive-VLM-8B"
CACHE_PATH="$NAVSIM_EXP_ROOT/recogdrive_agent_cache_dir_train"
OUTPUT_DIR="$NAVSIM_EXP_ROOT/recogdrive_stage2_training_ema_multinode_16gpus"

# ----------------- 2. è‡ªåŠ¨åŒ–åˆ†å¸ƒå¼é…ç½® (æ·±åº¦é€‚é… Luban/PET) -----------------

# [A] æ˜¾å¡é…ç½®ï¼šé€‚é…ä½ çš„ 8å¡ H20
GPUS_PER_NODE=8
NNODES=2  # ä½ ç”³è¯·äº† 2 å°æœºå™¨

# [B] è‡ªåŠ¨èŽ·å– Master IP å’Œ Rank
# æ ¹æ®ä½ çš„ debug.logï¼Œå¹³å°ä½¿ç”¨çš„æ˜¯ PET_ æˆ– DISTRIBUTED_ å‰ç¼€

if [ -n "$PET_MASTER_ADDR" ]; then
    # é€‚é… Luban/PET çŽ¯å¢ƒ
    echo "Detected Luban/PET Environment"
    MASTER_ADDR=$PET_MASTER_ADDR
    MASTER_PORT=${PET_MASTER_PORT:-29500}
    NODE_RANK=${DISTRIBUTED_NODE_RANK:-0}
    
elif [ -n "$VC_MASTER_HOSTS" ]; then
    # é€‚é… Volcano è°ƒåº¦çŽ¯å¢ƒ (å¤‡é€‰)
    echo "Detected Volcano Environment"
    # å–é€—å·å‰çš„ç¬¬ä¸€ä¸ª host
    MASTER_ADDR=$(echo $VC_MASTER_HOSTS | cut -d',' -f1)
    MASTER_PORT=${MASTER_PORT:-29500}
    NODE_RANK=${VC_TASK_INDEX:-0}

elif [ -n "$MLP_WORKER_0_HOST" ]; then
    # é€‚é…æ ‡å‡† MLP çŽ¯å¢ƒ (æ—§ç‰ˆ)
    echo "Detected Standard MLP Environment"
    MASTER_ADDR=$MLP_WORKER_0_HOST
    MASTER_PORT=${MLP_WORKER_0_PORT:-29500}
    NODE_RANK=$MLP_ROLE_INDEX

else
    # éƒ½æ²¡æœ‰ï¼Œå›žé€€åˆ°å•æœºè°ƒè¯•æ¨¡å¼
    echo "Warning: No distributed variables found. Fallback to localhost."
    MASTER_ADDR="127.0.0.1"
    MASTER_PORT=29500
    NODE_RANK=0
    NNODES=1
fi

echo "=================================================="
echo "   ðŸš€ Cluster Distributed Training Start"
echo "=================================================="
echo "Master Node: $MASTER_ADDR:$MASTER_PORT"
echo "My Rank:     $NODE_RANK"
echo "GPUs/Node:   $GPUS_PER_NODE"
echo "Total Nodes: $NNODES"
echo "=================================================="

# ----------------- 3. çŽ¯å¢ƒä¼˜åŒ– -----------------
# å¼ºåˆ¶ä½¿ç”¨ TCP é€šä¿¡ï¼Œé¿å… InfiniBand é…ç½®é—®é¢˜
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=0
export NCCL_SHM_DISABLE=0
export NCCL_SOCKET_FAMILY=AF_INET

export MASTER_ADDR=$MASTER_ADDR
export MASTER_PORT=$MASTER_PORT

# ... (å‰é¢çš„é…ç½®éƒ¨åˆ†ä¿æŒä¸å˜) ...

# ----------------- 4. å¯åŠ¨å‘½ä»¤ -----------------
# ä½ çš„ä»»åŠ¡åªå…è®¸æäº¤ä¸€ä¸ªè„šæœ¬ï¼Œè¿™ä¸ªå‘½ä»¤ä¼šåœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¹¶è¡Œæ‰§è¡Œ

torchrun \
    --nnodes=$NNODES \
    --node_rank=$NODE_RANK \
    --master_addr=$MASTER_ADDR \
    --master_port=$MASTER_PORT \
    --nproc_per_node=$GPUS_PER_NODE \
    $NAVSIM_DEVKIT_ROOT/navsim/planning/script/run_training_recogdrive_ema.py \
    agent=recogdrive_agent \
    agent.lr=1e-4 \
    agent.grpo=False \
    agent.vlm_path=$VLM_PATH \
    agent.cam_type='single' \
    agent.cache_hidden_state=True \
    agent.vlm_type="internvl" \
    agent.dit_type="small" \
    agent.sampling_method="ddim" \
    trainer.params.max_epochs=100 \
    experiment_name=training_recogdrive_agent_cluster \
    train_test_split=$TRAIN_TEST_SPLIT \
    cache_path=$CACHE_PATH \
    output_dir=$OUTPUT_DIR \
    use_cache_without_dataset=True \
    force_cache_computation=False \
    worker=sequential \
    dataloader.params.batch_size=32 \
    trainer.params.num_nodes=$NNODES \
    trainer.params.devices=$GPUS_PER_NODE \
    > train_mlp_rank${NODE_RANK}.log 2>&1